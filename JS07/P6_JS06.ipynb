{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP6_9Z0MtuVU"
      },
      "source": [
        "# **Praktikum 6**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipk0OohgtxOL"
      },
      "source": [
        "Lakukan percobaan penggunaan ANNOY, FAISS, dan HNSWLIB pada dataset sekunder berukuran besar (Micro Spotify) pada link berikut: https://www.kaggle.com/datasets/bwandowando/spotify-songs-with-attributes-and-lyrics/data . Download data dan load CSV filenya (pilih dataset yg pertama dari dua dataset). pilih hanya fitur numerik saja, dan lakukan normalisasi menggunakan StandardScaler. Lakukan pencarian track terdekat dan bandingkan hasilnya.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBLElkdZyBIG",
        "outputId": "87bafbc2-16cf-4d98-d751-51bedcc0cde2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Colab cache for faster access to the 'spotify-songs-with-attributes-and-lyrics' dataset.\n",
            "Path to dataset files: /kaggle/input/spotify-songs-with-attributes-and-lyrics\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"bwandowando/spotify-songs-with-attributes-and-lyrics\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsZ7FbV2tyuA",
        "outputId": "8e05cab3-064e-4a90-d269-46ee00bc8726"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exact NN done in 2.965 s\n",
            "Annoy done in 0.932 s\n",
            "HNSW done in 3.630 s\n",
            "FAISS IVF done in 0.416 s\n",
            "\n",
            "Top-5 neighbors for first song:\n",
            "Exact NN: [    0  6847  7747 17759 13172]\n",
            "Annoy:    [0, 6847, 7747, 17759, 13172]\n",
            "HNSW:     [    0  6847  7747 17759 13172]\n",
            "FAISS:    [    0  6847  7747 17759 13172]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import faiss\n",
        "from annoy import AnnoyIndex\n",
        "import hnswlib\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# -------------------------------\n",
        "# Load dataset\n",
        "# -------------------------------\n",
        "df = pd.read_csv(f\"{path}/songs_with_attributes_and_lyrics.csv\")\n",
        "features = ['danceability', 'energy', 'loudness', 'speechiness',\n",
        "            'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
        "\n",
        "# Ambil sample kecil biar cepet\n",
        "df_sampled = df.sample(n=20000, random_state=42)\n",
        "\n",
        "# Pilih fitur\n",
        "features = ['danceability', 'energy', 'loudness', 'speechiness',\n",
        "            'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
        "\n",
        "X = df_sampled[features].values\n",
        "\n",
        "# Standarisasi fitur\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "k = 10  # jumlah nearest neighbors\n",
        "\n",
        "# -------------------------------\n",
        "# Exact Nearest Neighbor (brute-force)\n",
        "# -------------------------------\n",
        "start = time.time()\n",
        "nn = NearestNeighbors(n_neighbors=k, algorithm='brute', metric='euclidean')\n",
        "nn.fit(X_scaled)\n",
        "dist_exact, idx_exact = nn.kneighbors(X_scaled)\n",
        "time_exact = time.time() - start\n",
        "print(f\"Exact NN done in {time_exact:.3f} s\")\n",
        "\n",
        "# -------------------------------\n",
        "# Annoy\n",
        "# -------------------------------\n",
        "start = time.time()\n",
        "f = X_scaled.shape[1]\n",
        "index_annoy = AnnoyIndex(f, 'euclidean')\n",
        "for i, v in enumerate(X_scaled):\n",
        "    index_annoy.add_item(i, v)\n",
        "index_annoy.build(10)\n",
        "idx_annoy = [index_annoy.get_nns_by_vector(v, k) for v in X_scaled]\n",
        "time_annoy = time.time() - start\n",
        "print(f\"Annoy done in {time_annoy:.3f} s\")\n",
        "\n",
        "# -------------------------------\n",
        "# HNSW\n",
        "# -------------------------------\n",
        "start = time.time()\n",
        "p_hnsw = hnswlib.Index(space='l2', dim=X_scaled.shape[1])\n",
        "p_hnsw.init_index(max_elements=X_scaled.shape[0], ef_construction=200, M=16)\n",
        "p_hnsw.add_items(X_scaled)\n",
        "p_hnsw.set_ef(200)\n",
        "idx_hnsw, dist_hnsw = p_hnsw.knn_query(X_scaled, k=k)\n",
        "time_hnsw = time.time() - start\n",
        "print(f\"HNSW done in {time_hnsw:.3f} s\")\n",
        "\n",
        "# -------------------------------\n",
        "# FAISS IVF\n",
        "# -------------------------------\n",
        "start = time.time()\n",
        "quantizer = faiss.IndexFlatL2(X_scaled.shape[1])\n",
        "index_faiss = faiss.IndexIVFFlat(quantizer, X_scaled.shape[1], 100, faiss.METRIC_L2)\n",
        "index_faiss.train(X_scaled)\n",
        "index_faiss.add(X_scaled)\n",
        "index_faiss.nprobe = 10\n",
        "dist_faiss, idx_faiss = index_faiss.search(X_scaled, k)\n",
        "time_faiss = time.time() - start\n",
        "print(f\"FAISS IVF done in {time_faiss:.3f} s\")\n",
        "\n",
        "# -------------------------------\n",
        "# Contoh tampilkan top-5 neighbors dari item pertama\n",
        "# -------------------------------\n",
        "print(\"\\nTop-5 neighbors for first song:\")\n",
        "print(f\"Exact NN: {idx_exact[0][:5]}\")\n",
        "print(f\"Annoy:    {idx_annoy[0][:5]}\")\n",
        "print(f\"HNSW:     {idx_hnsw[0][:5]}\")\n",
        "print(f\"FAISS:    {idx_faiss[0][:5]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G70duRUy01DF"
      },
      "source": [
        "Buat dan tuliskan analisa anda terhadap code diatas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLFNkyNy08Uy"
      },
      "source": [
        "Kode diatas digunakan untuk perbandingan 4 algoritma nearest neighbour, dan yang paling cepat adaalh FAISS, tetapi tidak terlalu akurat, lalu Annoy, memiliki hasil yang akurat terbesar kedua, lalu yang ketiga tercepat adaalh Exact NN, dan memiliki hasil yang paling akurat, yang terakhir paling cepat adalah HNSW, dan juga mendapat hasil yang akurat ke 3."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyN0DcvlWQq72RMGnI2fmwUf",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
